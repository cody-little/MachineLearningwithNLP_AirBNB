# -*- coding: utf-8 -*-
"""NLPwithAirBNB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12ucCtjPX-5UkbruG_rtkHbNJJw7NFWQN

#Natural Language Processing With Metadata: 
## A Comparison of Basic and Advanced Methods at Predicting AirBnB Price Ranges with Hybrid Feature Representations

**Summary**

This project compares naturual language processing feauture representations with metadata components for their efficacy in predicting a multiclass cost value of AirBNB listings in New York City. I compare SpaCy word embeddings to an optimized bag-of-words representation for the text description of the rental listing to see which method produces better results across various metrics. I test different models, then choose the best and optimize hyperperameters to create the best generalizable performance on a held out test set.

**Results**

Both feature representation methods proved very successful achieving well over a baseline accuracy level on a held out test set. After optimizing model selection random forest classifiers were the best at the task. Using grid search entropy splitting criterion was chosen. The bag-of-words text representation performed 3% better than a SpaCy word embeddings using the same metadata features, the same training, and the same test set. The results section also compares a Cohen's Kappa Score, F1 score and a visual confusion matrix.

### Data Intake, Cleaning and Exploration

#### Data Intake

I used Google Collab Notebooks for this analysis rather than a Jupyter Notebook running on my hardware. This allows me to remote host to a server owned by Google with much faster processing speeds and a lot more RAM than I have available. The code below simply imports the csv file for the project from my google drive. 

If you want to download the data for yoursself or to the see source I downloaded it from follow this link to the Kaggle page: https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data 

The SpaCy intake cell downloads the spacy module from github and installs it to the google collab notebook. If you are going to use the syntax or run these cells to see how the work you will need to do three things. If you don't do them the notebook won't work becuase it won't properly install and run the SpaCy module



1.   Run the cell with the SpaCy comment above it that installs SpaCy from github
2.   Restart the run time
3.   Repeat step one



The cell after the import data code is just a boiler plate import cell where I bring in things I may need, I usually just copy and paste this cell from project to project because it has most of the libraries I use and I can then just alter for anything else I may need
"""

#Data Intake#
!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=18SLzgQfrC5ck7DbaHa7BHx4ItDIi1LLY' -O AirBNB.csv

#SpaCy Intake#
!pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz

#Common libraries and things I use a lot#
import math
import pandas as pd
import numpy as np
import statsmodels.formula.api as smf
import matplotlib.pyplot as plt
from scipy import stats
from matplotlib import dates
import matplotlib.pyplot as plt
from datetime import datetime
import re
import calendar
import json
from sklearn.metrics import accuracy_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix, f1_score, ConfusionMatrixDisplay
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import BernoulliNB, ComplementNB, GaussianNB, MultinomialNB
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.neural_network import MLPClassifier 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn import tree
from sklearn.model_selection import train_test_split, KFold, StratifiedKFold
from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer
import spacy

"""#### Cleaning

The cleaning for this project is pretty standard since the data set was very workable coming from Kaggle. All I did was load it as a dataframe, drop columns I don't want for the analysis, and replace any NA's with a zero. 

While the cleaning wasn't too tedious there will be alot more to work with for the name column when I created the text feature representations.
"""

data = pd.read_csv("AirBNB.csv")
data = data.drop(['id','host_name','latitude','longitude','last_review','calculated_host_listings_count','availability_365','host_id'], axis = 1)
data = data.fillna(0)
data['name'] = data['name'].str.replace('\d+', '')
data = data.fillna(0)
data['name'] = data['name'].astype(str)
data.head()

"""#### Exploration"""

#Numerical Descriptives#
for column in data[['price', 'minimum_nights','number_of_reviews', 'reviews_per_month']]:
  print(data[column].describe())

#Categorical Variable Descriptives#
for column in data[['neighbourhood', 'neighbourhood_group','room_type']]:
  print(data[column].value_counts()/len(data))

data['neighbourhood_group'].value_counts().plot(kind='barh', color = ['red','blue','green'])

#Cool visualization of room type and price#
import plotly.express as px
xdata = data[data['price'] <= 300] 
fig = px.histogram(xdata, x="price", color="room_type")
fig.show()

fig = px.histogram(xdata, x="price", color="neighbourhood_group")
fig.show()

"""### Feature Creation, Text Representation Methods, and Data Set Preperation

#### Feature Creation
"""

#Create our predicted labels for a price range#
data['pricerange'] = data['price'].apply(lambda x: "Low" if x <= 75 else ("high" if x >= 175 else "medium"))
print(data['pricerange'].value_counts())
data.head(5)

"""#### Text Representation Methods

In this section I create two different text representation methods for the 'name' or textual feature component of the project. The first is a bag-of-words representation and the second is a 300 dimensional word embeddings using spaCy. Along with this I included some metadata feautures that I thought would be good predictors of price range labels. These included the neighbourhood group, neighbourhood, room type, and the number of reviews the listing has. 

After representing the text I split each representation into a train/validate/test split with equal proportions of outcome labels so everything is now ready to roll and we can fit some machine learning classifiers.

##### Bag of Words Creation
"""

vocab_size = 1500

vectorizer = CountVectorizer(max_features=vocab_size, ngram_range=(1,2))
X = vectorizer.fit_transform(data['name'])

bow_df = pd.DataFrame(X.toarray())
column_names = [str(i) for i in range(vocab_size)]

for k, v in vectorizer.vocabulary_.items():
  column_names[v] = k
bow_df.columns = column_names

bow_df["pricerange"] = data["pricerange"].values 
bow_df['neighbourhood_group'] = data['neighbourhood_group'].values
bow_df['room_type'] = data['room_type'].values
bow_df['number_of_reviews'] = data['number_of_reviews'].values

#look at it#
bow_df.head(5)

"""##### SpaCy Embedding Creation"""

# Commented out IPython magic to ensure Python compatibility.
nlp = spacy.load('en_core_web_md', disable=["parser", "ner"])
def tokenize(nlp, row):
    message = row["name"]
    ix = row["id"]
    tokens = nlp(message)
    return tokens
data['id'] = data.index + 1
# %time data_tag = data.apply(lambda x: tokenize(nlp, x), axis=1)

dimensions = 300

X_dict = {
    f"D{i}":[] for i in range(dimensions)
}

for row in data_tag:
  vector = row.vector
  for i in range(len(vector)):
    key = f"D{i}"
    X_dict[key].append(vector[i])

data_embed = pd.DataFrame(X_dict)
data_embed["pricerange"] = data["pricerange"].values 
data_embed['neighbourhood_group'] = data['neighbourhood_group'].values
data_embed['room_type'] = data['room_type'].values
data_embed['number_of_reviews'] = data['number_of_reviews'].values

data_embed.head(5)

"""##### Create Data Set Splits"""

BFtrain_set, BFtest_set = train_test_split(bow_df, train_size = .80, test_size = .20)
BFvalid_set, BFtest_set = train_test_split(BFtest_set,train_size = .50, test_size = .50 )

EMBtrain_set, EMBtest_set = train_test_split(data_embed, train_size = .80, test_size = .20)
EMBvalid_set, EMBtest_set = train_test_split(EMBtest_set,train_size = .50, test_size = .50 )

print('Bag of Words Data Split Predictor Variable')
print(BFtrain_set['pricerange'].value_counts()/len(BFtrain_set))
print(BFvalid_set['pricerange'].value_counts()/len(BFvalid_set))
print(BFtest_set['pricerange'].value_counts()/len(BFtest_set))
print('_____________________________________________________')
print()
print('Word Embedding Data Split Predictor Variable')
print(EMBtrain_set['pricerange'].value_counts()/len(EMBtrain_set))
print(EMBvalid_set['pricerange'].value_counts()/len(EMBvalid_set))
print(EMBtest_set['pricerange'].value_counts()/len(EMBtest_set))

"""### Model Training and Optimization on Validation Set

##### Make Training Set Splits and Get it Ready
"""

#Bag of Words Training Sets#
BFX_train = BFtrain_set.drop(['pricerange'], axis = 1)
BFX_train = pd.get_dummies(BFX_train)
BFy_train = BFtrain_set['pricerange']

#Word Embedding Training Sets#
EMBX_train = EMBtrain_set.drop(['pricerange'], axis=1)
EMBX_train = pd.get_dummies(EMBX_train)
EMBy_train = EMBtrain_set['pricerange']

"""##### Make Validation Splits and Get it Ready"""

#Bag of Words Valid#
BFX_valid = BFvalid_set.drop(['pricerange'], axis = 1)
BFX_valid = pd.get_dummies(BFX_valid)
BFy_valid = BFvalid_set['pricerange']

#Word Embedding Valid#
EMBX_valid = EMBvalid_set.drop(['pricerange'], axis = 1)
EMBX_valid = pd.get_dummies(EMBX_valid)
EMBy_valid = EMBvalid_set['pricerange']

"""##### Model Explorations
The next couple of cells explore three differenct classifiers and how they perform on our validation set with both the embedding text representation and the bag of words. I use this as an oppurtunity to optimize the bag of words representation by trying out different vocabulary sizes, ngram ranges, and whether or not to include stopwards. I compared three algorithims using the base classifier from sklearn. 

1. Bernoulli Naive Bayes
2. Random Forest
3. Ada Boost

I wanted to look at a few key things here, the first is the train time, I want the algorithim to be computationally effecient. Originally I had a linear support vector machine instead of the Ada Boost but it took 27 minutes to train and never even converged on its gradient descent. The second point of interest is a quadratically weighted Cohen's Kappa Score. I like to use this metric when first evaluating classifers for multilabel classification becuase it takes into account base probability and also gives or takes away credit for predictions that are close.

*For example: Labelling low when the true label is high lowers the metric more than labelling medium when the true label is high. A quadratically weighted kappa gives a good classifier evaluation metric for multiclass problems.*
"""

# Commented out IPython magic to ensure Python compatibility.
#Test out fitting a few different models#

#Bernoulli Naive Bayes Models#
print('Bernoulli Naive Bayes Training Times')
print('BOW')
# %time BernoulliModel_BF = BernoulliNB().fit(BFX_train,BFy_train)
print('EMBED')
# %time BernoulliModel_EMB = BernoulliNB().fit(EMBX_train,EMBy_train)

#RandomForestModels#
print('Random Forest Training Times')
print('BOW')
# %time RandomForest_BF = RandomForestClassifier(random_state = 500).fit(BFX_train,BFy_train)
print('EMBED')
# %time RandomForest_Emb = RandomForestClassifier(random_state = 500).fit(EMBX_train,EMBy_train)

#Ada Boost Classifier#
print('Ada Boost Training Times')
print('BOW')
# %time AdaBoost_BF = AdaBoostClassifier(random_state = 500).fit(BFX_train,BFy_train)
print('EMBED')
# %time AdaBoost_EMB = AdaBoostClassifier(random_state = 500).fit(EMBX_train,EMBy_train)

#Predict on the validation set and get some kappa scores#
BNB_BFpreds = BernoulliModel_BF.predict(BFX_valid)
BNB_EMBpreds = BernoulliModel_EMB.predict(EMBX_valid)
RF_BFpreds = RandomForest_BF.predict(BFX_valid)
RF_EMBpreds = RandomForest_Emb.predict(EMBX_valid)
AD_BFpreds = AdaBoost_BF.predict(BFX_valid)
AD_EMBpreds = AdaBoost_EMB.predict(EMBX_valid)

#Get Kappa Scores#
#Bernoulli Naive Bayes Kappa#
BNB_BFkappa = cohen_kappa_score(BNB_BFpreds, BFy_valid, weights='quadratic')
BNB_EMBkappa = cohen_kappa_score(BNB_EMBpreds, EMBy_valid, weights='quadratic')

#Random Forest Kappas#
RF_BFkappa = cohen_kappa_score(RF_BFpreds,BFy_valid, weights='quadratic')
RF_EMBkappa = cohen_kappa_score(RF_EMBpreds, EMBy_valid, weights='quadratic')

#Ada Boost Kappas#
AD_BFkappa = cohen_kappa_score(AD_BFpreds, BFy_valid, weights='quadratic')
AD_EMBkappa = cohen_kappa_score(AD_EMBpreds, EMBy_valid, weights='quadratic')

print('________________________________')
print(f'Bernoulli Naive Bayes Bag of Words Kappa is {BNB_BFkappa:.3f}, and Embedding Kappa is {BNB_EMBkappa:.3f}')
print(f'Random Forest Bag of Words Kappa is {RF_BFkappa:.3f}, and Embedding Kappa is {RF_EMBkappa:.3f}')
print(f'Ada Boost Algorithim Bag of Words Kappa is {AD_BFkappa:.3f}, and Embedding Kappa is {AD_EMBkappa:.3f}')
print('________________________________')

"""##### Best Model Optimization Across Text Representations

The best of the three tested models was the base Random Forest classifer. This isn't a huge surprise given how powerful random forests can be unconstrained. Since it is unconstrained I use a grid search with cross validation for both versions of the model (the BOW representation, and the Embedding). This will give me the ideal hyperperameters for the classifier to move forward to the test set. I will again be using Cohen's Kappa Score for the metric to optimize becuase of the previously mentioned advantages that could translate into higher success on the held out data set. 

The Random Forest Base Classifer Results from Model Selection

|Text Representation|Quadratic Kappa Score|
|---|---|
|Bag of Words|.482|
|SpaCy Embeddings|.486|

*These may change if the code has re-run because of random sampling of the data splits. I have optimized the BOW representation many times and the Random Forest classifer beat out bernoulli and ada boost every iteration.*


The cell below concatenates the validation set and training set from the inital model selection and bag-of-word optimization to create a larger final training set. Using this method I can take full advantage of the number of data objects I have within the data sets and leverage that extra size to create better models. I then use a grid search to exhaustively check for a few different splitting criterion for each random forest classifier (the embedding model and the bag-of-words model). I use a 3-k fold cross validation so the training and test sizes are about the same as the intial optimization strategy but don't take five hours to search the grid. I use cohen's kappa score again as the evaluation metric to get the best model preperation I can going into the held out set. The splitting criterion for each branch of the trees is a very important hyperperameter to check out for any analysis that uses some form of decision trees.
"""

# Commented out IPython magic to ensure Python compatibility.
#Combine Training and Validation sets#
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
BOW_Final_Train = pd.concat([BFtrain_set,BFvalid_set], ignore_index = True)
BOW_Final_TrainX = BOW_Final_Train.drop(['pricerange'], axis =1)
BOW_Final_TrainX = pd.get_dummies(BOW_Final_TrainX)
BOW_Final_Trainy = BOW_Final_Train['pricerange']
######################
#Make Embedding Data Sets#
EMB_Final_Train = pd.concat([EMBtrain_set,EMBvalid_set], ignore_index = True)
EMB_Final_TrainX = EMB_Final_Train.drop(['pricerange'], axis =1)
EMB_Final_TrainX = pd.get_dummies(EMB_Final_TrainX)
EMB_Final_Trainy = EMB_Final_Train['pricerange']
######################

#######################
#Set up grid search for criterion and forest size#
kappa_scorer = make_scorer(cohen_kappa_score)
GridRandForest_BOW = GridSearchCV(RandomForestClassifier(), param_grid={'n_estimators': [100], 'criterion': ['gini', 'entropy']}, cv = 3, scoring = kappa_scorer)
GridRandForest_EMB = GridSearchCV(RandomForestClassifier(), param_grid={'n_estimators': [100], 'criterion': ['gini', 'entropy']}, cv = 3, scoring=kappa_scorer)
#######################
#Fit the Grid Search To get optimal parameters#
# %time GridRandForest_BOW.fit(BOW_Final_TrainX,BOW_Final_Trainy)
# %time GridRandForest_EMB.fit(EMB_Final_TrainX,EMB_Final_Trainy)

BOWBestParams = GridRandForest_BOW.best_params_
BOWBestScore = GridRandForest_BOW.best_score_
print(BOWBestParams)
print(BOWBestScore)

EMBBestParams = GridRandForest_EMB.best_params_
EMBBestScore = GridRandForest_EMB.best_score_
print(EMBBestParams)
print(EMBBestScore)

"""### Final Model Creation and Results

Now that we know entropy which uses information gain is the best splitting criterion we can fit our models with these hyperperameters and test them out. Below is a cell that creates the final X and y sets and then fits the classifiers returning a couple different metrics on the results.

**Results**
The results cell gives a comparison of how each feature space performed at this task. The bag-of-words representation space performed marginally better with about a 3% higher accuracy than the word embedding space. This could come to many as a surprise. Bag-of-words is a much simpler representation but that doesn't mean it can't be highly effective. The confusion matrix displays give us a better idea of what the classifiers incorrectly predicted for each group. The loss by the word embeddings random forest seems to have come from misclassifications of high priced rentals where they were incorrectly classified as medium. Both models achieved well over a baseline accuracy with this multiclass label task using a hybrid text and metadata feature space showing this is a viable method to quickly classifiy rental units in price ranges so that users can more easily sort them. Comparing different feature representations for text and how they perform with metadata is an important aspect of machine learning algorithims. This project goes to show that a more complication method such as a 300 dimensional word embedding may not always be the best choice, a bag-of-words representation performed marginally better and was computationally more efficent.
"""

###Create Final Test Sets#
BOW_Final_TESTX = BFtest_set.drop(['pricerange'], axis =1)
BOW_Final_TESTX = pd.get_dummies(BOW_Final_TESTX)
BOW_Final_TESTy = BFtest_set['pricerange']

EMB_Final_TESTX = EMBtest_set.drop(['pricerange'], axis =1)
EMB_Final_TESTX = pd.get_dummies(EMB_Final_TESTX)
EMB_Final_TESTy = EMBtest_set['pricerange']

##Fit Best Hyperperameter Model for each representation#

RandomForestBOWFinal = RandomForestClassifier(n_estimators=100,criterion='entropy').fit(BOW_Final_TrainX,BOW_Final_Trainy)
RandomForestEMBFinal = RandomForestClassifier(n_estimators = 100, criterion = 'entropy').fit(EMB_Final_TrainX, EMB_Final_Trainy)

##Predict onto the held out test set#
BOWpreds = RandomForestBOWFinal.predict(BOW_Final_TESTX)
EMBpreds = RandomForestEMBFinal.predict(EMB_Final_TESTX)

BFtest_set['predictions'] = BOWpreds
EMBtest_set['predictions'] = EMBpreds

#Get Scores for a variety of Metrics on Each to understand tradeoffs#
BOWacc = accuracy_score(BOW_Final_TESTy,BOWpreds)
EMBacc = accuracy_score(EMB_Final_TESTy, EMBpreds)
BOWkap = cohen_kappa_score(BOW_Final_TESTy,BOWpreds,weights = 'quadratic')
EMBkap = cohen_kappa_score(BOW_Final_TESTy,BOWpreds, weights = 'quadratic')
BOWf1 = f1_score(BOW_Final_TESTy,BOWpreds, average='macro')
EMBf1 = f1_score(EMB_Final_TESTy, EMBpreds, average='macro')
BOWconf = confusion_matrix(BOW_Final_TESTy,BOWpreds)
EMBconf = confusion_matrix(EMB_Final_TESTy, EMBpreds)

#Display Creation Cell#
print('___________________________________________')
print('Final Results on Test Set For Each Method')
print('___________________________________________')
print()
print('Optimized Bag of Words Representation with Optimized Random Forest Classifier')
print()
print(f'Accuracy: {BOWacc:.3f}, Kappa: {BOWkap:.3f}')
print(f'F1 Score: {BOWf1:.3f},')
print()
ConfusionMatrixDisplay(BOWconf,["Low","High","Medium"]).plot(values_format = '4g')
plt.show()
print()
print('__________________________________________')
print('Word Embeddings Representation with Optimized Random Forest Classifier')
print()
print(f'Accuracy: {EMBacc:.3f}, Kappa: {EMBkap:.3f}')
print(f'F1 Score: {EMBf1:.3f},')
print()
ConfusionMatrixDisplay(EMBconf,["Low","High","Medium"]).plot(values_format = '4g')
plt.show()
print()